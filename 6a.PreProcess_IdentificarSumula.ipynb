{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('d:\\\\Users\\\\Patri\\\\Documents\\\\1.TCC\\\\Notebooks\\\\WebScrapAcordaosPDF\\\\NLTK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.read_csv('Acordaos2020tratado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão das colunas de texto em string, elimina valores nulos\n",
    "colunas = ('NomeRelator', 'Ementa', 'Acordao', 'Relatorio', 'Voto', 'VotoVencedor', 'DeclaracaoVoto')\n",
    "for coluna in colunas: df[coluna] = df[coluna].astype('str')\n",
    "\n",
    "# Converte a coluna 'Data' para o formato datetime\n",
    "df['Data'] = pd.to_datetime(df['Data'])\n",
    "\n",
    "df = df.fillna('')\n",
    "df = df.replace(np.nan,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pesquisar ocorrências da palavra Súmula e variações\n",
    "pesquisar = ['súmula', 'sumula', 'súmulas', 'sumulas']\n",
    "pesquisa_str = \"|\".join(pesquisar)\n",
    "print (pesquisa_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas=['Voto', 'Ementa', 'Relatorio', 'Acordao', 'VotoVencedor', 'DeclaracaoVoto']\n",
    "df[colunas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Contar as menções a súmula em cada seção do Acórdão\n",
    "colunas=['Voto', 'Ementa', 'Relatorio', 'Acordao', 'VotoVencedor', 'DeclaracaoVoto']\n",
    "resultado = [[\"Pesquisando:\",pesquisa_str],['Total de Documentos',len(df[colunas])]]\n",
    "for count, colunas in enumerate(colunas):\n",
    "    resultado.append(['Contém em '+ colunas, len(df[df[colunas].str.contains(pesquisa_str, na=False, case=False)])])\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Seleciona uma coluna para extrair um texto de um acórdão com a palavra súmula\n",
    "colunas=['Voto', 'Ementa', 'Relatorio', 'Acordao', 'VotoVencedor', 'DeclaracaoVoto']\n",
    "pesquisar = ['súmula', 'sumula', 'súmulas', 'sumulas']\n",
    "pesquisa_str = \"|\".join(pesquisar)\n",
    "\n",
    "for count, coluna in enumerate(colunas): print (count, coluna)\n",
    "\n",
    "coluna_escolhida = colunas[5]\n",
    "df_sumula = df[df[coluna_escolhida].str.contains(pesquisa_str, na=False, case=False)]\n",
    "df_sumula_coluna = df_sumula[colunas]\n",
    "display(df_sumula_coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recebe um texto ou series e retorna os tokens\n",
    "def tokeniza(texto):\n",
    "    if type(texto) == \"Series\":\n",
    "        acordao_text = texto.to_string()\n",
    "    else:\n",
    "        acordao_text = str(texto)\n",
    "    acordao_text = acordao_text.lower() # coloca tudo em minúsculo\n",
    "    acordao_text = re.sub('(º)', ' ', acordao_text) # remove 'º' substituindo por espaço\n",
    "    acordao_words = RegexpTokenizer(r'\\w+') # remove pontuação ao selecionar apenas palavras\n",
    "    acordao_tokens = acordao_words.tokenize(acordao_text) # tokeniza (separa as palavras)\n",
    "\n",
    "    # Extrair Stopwords em Português\n",
    "    pt_stops = set(stopwords.words('portuguese'))\n",
    "    pt_stops.update(['fls', 'cuida', 'ª', 'n', 'fl'])\n",
    "    words = (acordao_tokens)\n",
    "    lista_words = [word for word in words if word not in pt_stops] # remove stopwords\n",
    "    if not len(lista_words): lista_words = []\n",
    "    return lista_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Tokeniza trechos do acórdão e salva tokens em uma nova coluna\n",
    "colunas=['Voto', 'Ementa', 'Relatorio', 'Acordao', 'VotoVencedor', 'DeclaracaoVoto']\n",
    "\n",
    "for coluna in colunas:\n",
    "    df['t_'+coluna] = df[coluna].apply(tokeniza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica ocorrências da palavra \"Súmula\" e informações adicionais ao redor\n",
    "# Recebe um texto tokenizado e retorna um dataframe\n",
    "def localiza_sumula(texto):\n",
    "\n",
    "    # Tokeniza texto, remove stopwords e pontuação\n",
    "    listOfTokens = texto\n",
    "       \n",
    "    # Estabelece variações da palavra 'súmula'\n",
    "    words2find = ['súmula', 'sumula', 'súmulas', 'sumulas']\n",
    "    context = 4\n",
    "\n",
    "    # Encontrar ocorrências da string de pesquisa e mostrar as palavras em torno\n",
    "    # https://github.com/sgsinclair/alta/blob/a482d343142cba12030fea4be8f96fb77579b3ab/ipynb/utilities/Concordances.ipynb\n",
    "\n",
    "    def makeConc(words2conc,list2FindIn,context2Use):\n",
    "        end = len(list2FindIn)\n",
    "\n",
    "        # Nomear as colunas das informações da súmula\n",
    "        col_conteudo = \"Conteudo\"\n",
    "        col_posicao = \"Posicao\"\n",
    "        col_num_sum = \"Sumula n\"\n",
    "        col_tribunal = \"Tribunal\"\n",
    "        col_vinculante = \"Vinculacao\"\n",
    "        col_aplica = \"Aplicabilidade\"\n",
    "        colunas_sumulas = (col_conteudo, col_posicao, col_num_sum, col_tribunal, col_vinculante, col_aplica)\n",
    "\n",
    "        concDF = pd.DataFrame(columns = colunas_sumulas)\n",
    "\n",
    "        for location in range(end):\n",
    "            for word2conc in words2conc:\n",
    "                if list2FindIn[location] == word2conc:\n",
    "                    if (location - context2Use) < 0:\n",
    "                        beginCon = 0\n",
    "                    else:\n",
    "                        beginCon = location - context2Use\n",
    "\n",
    "                    if (location + context2Use) > end:\n",
    "                        endCon = end\n",
    "                    else:\n",
    "                        endCon = location + context2Use\n",
    "\n",
    "                    theContext = (list2FindIn[location:endCon])\n",
    "                    concordanceLine = ' '.join(theContext)\n",
    "                                      \n",
    "                    # Encontrar as informações da súmula\n",
    "                    txt_conteudo = concordanceLine\n",
    "                    txt_posicao = str(location)\n",
    "                    txt_num_sum = \"\"\n",
    "                    txt_tribunal = \"\"\n",
    "                    txt_vinculante = \"\"\n",
    "                    txt_aplica = \"\"\n",
    "                    for location_number in range (beginCon,endCon):\n",
    "                        achou = list2FindIn[location_number]\n",
    "                        tribunais = [\"carf\", \"stf\", \"stj\", \"supremo\", \"tst\", \"trt\"]\n",
    "                        inaplicaveis = [\"inaplicabilidade\", \"não\", \"inaplicável\", \"incabível\", \"inaplica\"]\n",
    "                        if achou.isnumeric() and location_number > location and int(achou) <= 161 : txt_num_sum = int(achou)\n",
    "                        if achou in tribunais    and achou not in txt_tribunal: txt_tribunal = achou\n",
    "                        if achou == \"vinculante\" and achou not in txt_vinculante: txt_vinculante = achou\n",
    "                        if achou in inaplicaveis and achou not in txt_aplica: txt_aplica = achou\n",
    "                    \n",
    "                    nova_linha = {\n",
    "                        col_conteudo   : txt_conteudo,\n",
    "                        col_posicao    : txt_posicao,\n",
    "                        col_num_sum    : txt_num_sum,\n",
    "                        col_tribunal   : txt_tribunal,\n",
    "                        col_vinculante : txt_vinculante,\n",
    "                        col_aplica     : txt_aplica\n",
    "                    }                        \n",
    "                    if bool(txt_num_sum) : concDF = concDF.append(nova_linha, ignore_index=True)\n",
    "\n",
    "        return concDF\n",
    "\n",
    "    concDF2 = makeConc(words2find,listOfTokens,int(context))\n",
    "\n",
    "    return concDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identifica o número das súmulas CARF aplicáveis\n",
    "# Recebe texto tokenizado (constante nas colunas t_secao)\n",
    "# Retorna lista de números\n",
    "def identifica_sumulas(t_coluna):\n",
    "    if not len(t_coluna):\n",
    "        return []\n",
    "    else:\n",
    "        df_sumula = localiza_sumula(t_coluna)\n",
    "        # Filtrar apenas Súmulas do CARF aplicáveis    \n",
    "        df_carf = df_sumula[['Tribunal','Sumula n','Aplicabilidade']]\n",
    "        df_carf = df_carf[(df_carf['Tribunal'] == 'carf') & (df_carf['Aplicabilidade'] == '')]\n",
    "        df_carf = df_carf.drop_duplicates()\n",
    "        df_carf = df_carf['Sumula n'].sort_values().tolist()\n",
    "        if len(df_carf):\n",
    "            return df_carf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#\n",
    "# Função mais demorada desse notebook!!!!!\n",
    "#\n",
    "# Aplica a função de listar em uma nova coluna o número das súmulas de cada seção do acordão:\n",
    "# Utiliza o texto tokeniza de cada seção (voto, ementa, relatório, acordão, voto vencedor e declaração de voto), \n",
    "# localiza nele as ocorrências da palavra súmula e suas variações, extrai informações adicionais (tribunal, aplicabilidade, número)\n",
    "# e retorna uma lista com os números das súmulas CARF aplicadas naquele texto. O resultado é inserido em uma nova coluna no dataframe.\n",
    "# Entrada: colunas t_seção\n",
    "# Saída: colunas s_seção\n",
    "\n",
    "colunas=['Voto', 'Ementa', 'Relatorio', 'Acordao', 'VotoVencedor', 'DeclaracaoVoto']\n",
    "# colunas=['DeclaracaoVoto']\n",
    "\n",
    "for coluna in colunas:\n",
    "    df['s_'+coluna] = df['t_'+coluna].apply(identifica_sumulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df.to_csv('Acordaos2020sumulado.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd03ea523bc2d4f869847872ce3cd57df8231ee0b54777ea6b7d40abc7c29d8b996",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}