{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('d:\\\\Users\\\\Patri\\\\Documents\\\\1.TCC\\\\Notebooks\\\\WebScrapAcordaosPDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(executable_path=r\"C:\\chromedriver\\chromedriver.exe\", options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Webscrapping CARF Precedentes das Súmulas PDfs\n",
    "inicio = datetime.now()\n",
    "hora_inicio = inicio.strftime(\"%H:%M:%S\")\n",
    "\n",
    "for count, num_acordao in enumerate(acordaosabaixar):\n",
    "    if count <= 1174: continue\n",
    "    # Carrega página de pesquisa\n",
    "    driver.get(\"https://carf.fazenda.gov.br/sincon/public/pages/ConsultarJurisprudencia/consultarJurisprudenciaCarf.jsf\")\n",
    "    driver.find_element(By.CSS_SELECTOR, \".container\").click()\n",
    "    NumAcordao = driver.find_element(By.ID, \"valor_pesquisa1\")\n",
    "    NumAcordao.send_keys(num_acordao)\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/table/tbody/tr[2]/td/div/div[3]/div[2]/form/div/div[2]/div[2]/table/tbody/tr/td[2]/label/input\").click()\n",
    "    driver.find_element(By.ID, \"botaoPesquisarCarf\").click()\n",
    "    WebDriverWait(driver, 30000).until(EC.presence_of_element_located((By.ID, \"tblJurisprudencia:0:numDecisao\")))\n",
    "    driver.find_element(By.ID, \"tblJurisprudencia:0:numDecisao\").click()\n",
    "\n",
    "    #   Clicar no botão de download do PDF:\n",
    "    WebDriverWait(driver, 30000).until(EC.presence_of_element_located((By.XPATH, \"//div/a/img\")))\n",
    "    driver.find_element(By.XPATH, \"//div/a/img\").click()  \n",
    "\n",
    "    # #   Clicar no botão de Voltar:  \n",
    "    # driver.find_element(By.XPATH, \"//div[3]/input\").click() \n",
    "    decorrido = datetime.now() - inicio\n",
    "    expectativa = decorrido / (count + 1) * len(acordaosabaixar)\n",
    "    if decorrido > expectativa: \n",
    "        restante = 0 \n",
    "    else: \n",
    "        restante = expectativa - decorrido\n",
    "    log_line= str(decorrido)[:-7] + \" \" + str(expectativa)[:-7] + \" \" + str(restante)[:-7] + \" \" + str(num_acordao) + \" \" + str(count) + \"/\" + str(len(acordaosabaixar))\n",
    "    print(log_line)\n",
    "\n",
    "    # Clicar no botão de Voltar:  \n",
    "    driver.find_element(By.XPATH, \"//div[3]/input\").click()   \n",
    "\n",
    "    # Clicar no botão de Voltar:  \n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/table/tbody/tr[2]/td/div/div[3]/div[2]/form/div[2]/input[1]\").click()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "page = requests.get(\"http://idg.carf.fazenda.gov.br/jurisprudencia/sumulas-carf/quadro-geral-de-sumulas-1\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragrafos = soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rotina para iterar sobre a lista de Súmulas e Precedentes e gerar um DataFrame\n",
    "sumulaseprecedentes = pd.DataFrame(columns=(\"Sumula\", \"TextoSumula\", \"Precedente\"))\n",
    "precedentes = []\n",
    "sumula_num = 0\n",
    "itera_precedentes = False\n",
    "\n",
    "for count, valor in enumerate(paragrafos):   \n",
    "    linha = paragrafos[count].get_text()\n",
    "    linha = linha.replace(u'\\xa0', u' ') # Converte non-breaking space em space\n",
    "\n",
    "    if len(linha) == 0 : continue\n",
    "\n",
    "    # Identifica o número da súmula\n",
    "    if linha[:6] == \"Súmula\" : \n",
    "        sumula_num = int(re.findall('(?:Súmula)(?:.*?)(\\d*$)', linha)[0])\n",
    "        vinculante = \"\"\n",
    "        continue\n",
    "\n",
    "    # Identifica o número dos precedentes\n",
    "    if itera_precedentes == True : \n",
    "        if re.search('(Vinculante)', linha) :\n",
    "            vinculante = re.findall('(?:Vinculante, conforme )(.*)', linha)[0]\n",
    "\n",
    "        linha = re.sub('(nº )', '', linha)\n",
    "        linha = re.sub('(Acórdão )', '', linha)\n",
    "        linha = re.sub('(CSRF/)', '', linha)\n",
    "        linha = re.sub('(CSRF )', '', linha)\n",
    "        linha = re.sub('(PLENO )', '', linha)        \n",
    "        linha = re.sub('(de )', ' ', linha)\n",
    "        linha = re.sub('(e )', ' ', linha)\n",
    "        linha = re.sub('(\\d+/\\d+/\\d+)', '', linha)        \n",
    "        linha = re.sub('(,)', '', linha)\n",
    "        linha = re.sub('(;)', '', linha)\n",
    "        linha = re.sub('(\\. )', ' ', linha)\n",
    "        linha = re.sub('(\\.$)', '', linha)\n",
    "        linha = re.sub('( \\.)', ' ', linha)     \n",
    "        linha = re.sub('(- )', '-', linha)\n",
    "        listaprecedentes = re.findall('(\\d*-\\d*.\\d*?\\S)(?:,|;| |\\n|$)', linha)\n",
    "        \n",
    "        # if count in range (30,50): print(count, sumula_num, linha, listaprecedentes)    \n",
    "        # if sumula_num in range (161): print(count, sumula_num, linha, listaprecedentes)    \n",
    "        for item in listaprecedentes:            \n",
    "            sumulaseprecedentes = sumulaseprecedentes.append({\n",
    "                \"Sumula\": sumula_num, \n",
    "                \"TextoSumula\": texto_sum, \n",
    "                \"Precedente\": item,\n",
    "                \"Vinculante\": vinculante\n",
    "                }, ignore_index=True)\n",
    "        # print (\"Quantidade de precedentes:\", len(listaprecedentes))\n",
    "\n",
    "        # Reinicializa a rotina e a lista de precedentes:\n",
    "        precedentes = []\n",
    "        itera_precedentes = False\n",
    "        vinculante = \"\"\n",
    "        continue\n",
    "    \n",
    "    # Identifica a linha anterior ao número dos precedentes e dispara a rotina \"itera_precedentes\"\n",
    "    # if linha[:22] == \"Acórdãos Precedentes:\" or linha[:22] == \"AcórdãosPrecedentes:\" : \n",
    "    if re.findall('(Acórdãos).*?(Precedentes:)', linha): \n",
    "        itera_precedentes = True\n",
    "        continue\n",
    "\n",
    "    # Identifica se é súmula vinculante\n",
    "    if re.search('(Vinculante)', linha) :\n",
    "        vinculante = re.findall('(?:Vinculante, conforme )(.*)', linha)[0]\n",
    "        if len (sumulaseprecedentes.query('Sumula == ' + str(sumula_num))):\n",
    "            sumulaseprecedentes.loc[sumulaseprecedentes['Sumula'] == sumula_num, ['Vinculante']] = vinculante\n",
    "        # print(vinculante)\n",
    "\n",
    "    # Captura o texto da súmula\n",
    "    texto_sum = linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acordaosabaixar = sumulaseprecedentes['Precedente'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 146 - Acórdão '204-00304' É uma Resolução, não um Acórdão\n",
    "# 277 - Acórdão nº CSRF/04-00.6676, de 19/09/2007 não encontrado - Súmula 39\n",
    "# 955 - Acórdão nº 3802-000.570, de 05/07/2011 não encontrado - Súmula 126\n",
    "# Acórdão nº 3202-003.057 não encontrado - Súmula 155\n",
    "# 03201-002.029, corrigir para 3201-002.029\n",
    "# 949,3201-002.860 recisou ser corrigido manualmente para 3201-002.860\n",
    "# 9303-004.949 precisou ser inserido manualmente\n",
    "\n",
    "# acordaosabaixar('03201-002.029')\n",
    "\n",
    "# acordaosabaixar.remove('204-00304')\n",
    "# acordaosabaixar.remove('04-00.6676')\n",
    "# acordaosabaixar.remove('3802-000.570')\n",
    "# acordaosabaixar.append('9303-004.949')\n",
    "# acordaosabaixar.remove('3202-003.057')\n",
    "\n",
    "# acordaosabaixar[1174]\n",
    "len(acordaosabaixar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumulaseprecedentes['Sumula'].value_counts().sort_index().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra = sumulaseprecedentes[['Sumula', 'Precedente']]\n",
    "amostra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amostra = sumulaseprecedentes[['Sumula', 'Precedente']]\n",
    "# lista_acordaos = amostra.query(\"Sumula == [137, 128, 17, 157, 108, 1, 49, 2]\")['Precedente'].values\n",
    "# lista_acordaos\n",
    "lista_acordaos = amostra.query(\"Sumula == [2]\")['Precedente'].values\n",
    "lista_acordaos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Webscrapping para baixar PDFs de uma súmula expecífica\n",
    "acordaosabaixar = lista_acordaos\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(executable_path=r\"C:\\chromedriver\\chromedriver.exe\", options=options)\n",
    "\n",
    "# Webscrapping CARF Precedentes das Súmulas PDfs\n",
    "inicio = datetime.now()\n",
    "hora_inicio = inicio.strftime(\"%H:%M:%S\")\n",
    "\n",
    "for count, num_acordao in enumerate(acordaosabaixar):\n",
    "    # if count <= 1174: continue\n",
    "    # Carrega página de pesquisa\n",
    "    driver.get(\"https://carf.fazenda.gov.br/sincon/public/pages/ConsultarJurisprudencia/consultarJurisprudenciaCarf.jsf\")\n",
    "    driver.find_element(By.CSS_SELECTOR, \".container\").click()\n",
    "    NumAcordao = driver.find_element(By.ID, \"valor_pesquisa1\")\n",
    "    NumAcordao.send_keys(num_acordao)\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/table/tbody/tr[2]/td/div/div[3]/div[2]/form/div/div[2]/div[2]/table/tbody/tr/td[2]/label/input\").click()\n",
    "    driver.find_element(By.ID, \"botaoPesquisarCarf\").click()\n",
    "    WebDriverWait(driver, 30000).until(EC.presence_of_element_located((By.ID, \"tblJurisprudencia:0:numDecisao\")))\n",
    "    driver.find_element(By.ID, \"tblJurisprudencia:0:numDecisao\").click()\n",
    "\n",
    "    #   Clicar no botão de download do PDF:\n",
    "    WebDriverWait(driver, 30000).until(EC.presence_of_element_located((By.XPATH, \"//div/a/img\")))\n",
    "    driver.find_element(By.XPATH, \"//div/a/img\").click()  \n",
    "\n",
    "    # #   Clicar no botão de Voltar:  \n",
    "    # driver.find_element(By.XPATH, \"//div[3]/input\").click() \n",
    "    decorrido = datetime.now() - inicio\n",
    "    expectativa = decorrido / (count + 1) * len(acordaosabaixar)\n",
    "    if decorrido > expectativa: \n",
    "        restante = 0 \n",
    "    else: \n",
    "        restante = expectativa - decorrido\n",
    "    log_line= str(decorrido)[:-7] + \" \" + str(expectativa)[:-7] + \" \" + str(restante)[:-7] + \" \" + str(num_acordao) + \" \" + str(count) + \"/\" + str(len(acordaosabaixar))\n",
    "    print(log_line)\n",
    "\n",
    "    # Clicar no botão de Voltar:  \n",
    "    driver.find_element(By.XPATH, \"//div[3]/input\").click()   \n",
    "\n",
    "    # Clicar no botão de Voltar:  \n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/table/tbody/tr[2]/td/div/div[3]/div[2]/form/div[2]/input[1]\").click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscrapping para pegar o número do Processo a partir do Acórdão\n",
    "\n",
    "dfA = pd.DataFrame(columns = [\n",
    "    \"numProcesso\",\n",
    "    \"numDecisao\"\n",
    "])\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"headless\")\n",
    "driver = webdriver.Chrome(executable_path=r\"C:\\chromedriver\\chromedriver.exe\", options=options)\n",
    "\n",
    "# Webscrapping CARF Precedentes das Súmulas PDfs\n",
    "inicio = datetime.now()\n",
    "hora_inicio = inicio.strftime(\"%H:%M:%S\")\n",
    "\n",
    "for count, num_acordao in enumerate(lista_acordaos):\n",
    "    # if count <= 85 : continue\n",
    "    # Carrega página de pesquisa\n",
    "    driver.get(\"https://carf.fazenda.gov.br/sincon/public/pages/ConsultarJurisprudencia/consultarJurisprudenciaCarf.jsf\")\n",
    "    driver.find_element(By.CSS_SELECTOR, \".container\").click()\n",
    "    NumAcordao = driver.find_element(By.ID, \"valor_pesquisa1\")\n",
    "    NumAcordao.send_keys(num_acordao)\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/table/tbody/tr[2]/td/div/div[3]/div[2]/form/div/div[2]/div[2]/table/tbody/tr/td[2]/label/input\").click()\n",
    "    driver.find_element(By.ID, \"botaoPesquisarCarf\").click()\n",
    "    WebDriverWait(driver, 30000).until(EC.presence_of_element_located((By.ID, \"tblJurisprudencia:0:numDecisao\")))\n",
    "    driver.find_element(By.ID, \"tblJurisprudencia:0:numDecisao\").click()\n",
    "\n",
    "    # Capturar dados para o dataset\n",
    "    numProcesso=driver.find_element(By.ID, \"formAcordaos:numProcesso\").text\n",
    "    numDecisao=driver.find_element(By.ID, \"formAcordaos:numDecisao\").text\n",
    "\n",
    "    # Inserir dados do Acórdão no Dataframe\n",
    "    dfA = dfA.append({ \n",
    "        \"numProcesso\"  : str(numProcesso), \n",
    "        \"numDecisao\"   : str(numDecisao)\n",
    "    }, ignore_index=True)\n",
    "        \n",
    "    # #   Clicar no botão de download do PDF:\n",
    "    # WebDriverWait(driver, 30000).until(EC.presence_of_element_located((By.XPATH, \"//div/a/img\")))\n",
    "    # driver.find_element(By.XPATH, \"//div/a/img\").click()  \n",
    "\n",
    "    # Clicar no botão de Voltar:  \n",
    "    driver.find_element(By.XPATH, \"//div[3]/input\").click()   \n",
    "\n",
    "    # Clicar no botão de Voltar:  \n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/table/tbody/tr[2]/td/div/div[3]/div[2]/form/div[2]/input[1]\").click()\n",
    "\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('d:\\\\Users\\\\Patri\\\\Documents\\\\1.TCC\\\\Notebooks\\\\WebscrapSúmula\\\\Amostra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA.to_csv('Procs_Acordaos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA = pd.read_csv('Procs_Acordaos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acordaosabaixar = sumulaseprecedentes['Precedente'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA['numDecisao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pikepdf\n",
    "import pikepdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Decrypt PDFs to DECRYPT folder\n",
    "\n",
    "lista = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "len(lista)\n",
    "\n",
    "if not 'DECRYPT' in os.listdir(): os.mkdir(\"DECRYPT\")\n",
    "\n",
    "inicio = datetime.now()\n",
    "\n",
    "for count, arquivo in enumerate(lista):\n",
    "    filename=lista[count]\n",
    "    \n",
    "    with pikepdf.open(filename) as pdf:\n",
    "        num_pages = len(pdf.pages)\n",
    "        del pdf.pages[-1]\n",
    "        pdf.save('DECRYPT\\\\' + filename)\n",
    "\n",
    "    decorrido = datetime.now() - inicio\n",
    "    expectativa = decorrido / (count+1) * len(lista)\n",
    "    if decorrido > expectativa: \n",
    "        restante = 0 \n",
    "    else: \n",
    "        restante = expectativa - decorrido\n",
    "    print (count, str(decorrido)[:-7], str(expectativa)[:-7], str(restante)[:-7], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('DECRYPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfminer\n",
    "# from pdfminer.high_level import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/pdf-text-extraction-in-python-5b6ab9e92dd\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "\n",
    "def convert_pdf_to_string(file_path):\n",
    "\n",
    "\toutput_string = StringIO()\n",
    "\twith open(file_path, 'rb') as in_file:\n",
    "\t    parser = PDFParser(in_file)\n",
    "\t    doc = PDFDocument(parser)\n",
    "\t    rsrcmgr = PDFResourceManager()\n",
    "\t    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "\t    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\t    for page in PDFPage.create_pages(doc):\n",
    "\t        interpreter.process_page(page)\n",
    "\n",
    "\treturn(output_string.getvalue())\n",
    "\n",
    "lista = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "\n",
    "inicio = datetime.now()\n",
    "\n",
    "data_prec = pd.DataFrame(columns = ['Completo'])\n",
    "\n",
    "for count, arquivo in enumerate(lista):\n",
    "    textotodo = convert_pdf_to_string(arquivo)\n",
    "    data_prec = data_prec.append({ 'Completo' : textotodo }, ignore_index=True)\n",
    "\n",
    "    decorrido = datetime.now() - inicio\n",
    "    expectativa = decorrido / (count+1) * len(lista)\n",
    "    if decorrido > expectativa: \n",
    "        restante = 0 \n",
    "    else: \n",
    "        restante = expectativa - decorrido\n",
    "\n",
    "    print (count, str(decorrido)[:-7], str(expectativa)[:-7], str(restante)[:-7], arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prec.to_csv('acordaos_textocompleto.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrai_texto_acordao(texto_ac):\n",
    "    regex_num_proc = '(?:[^\\d]|^)(\\d{5}\\.\\d{6}\\/\\d{4}-\\d{2})(?:[^\\d]|$)' # obtém um número de processo no formato 00000.000000/0000-00\n",
    "    regex_num_ac = '(?:[^\\d]|^)(?P<acordao>\\d{2,4}-\\d{2,4}\\.\\d{3})(?:[^\\d]|$)' # obtém um número de acórdão no formato 00-00.000 até 0000-0000.000\n",
    "\n",
    "    proc_num = list(set(re.findall(regex_num_proc, texto_ac))) # localiza nº processo e exclui repetições\n",
    "    if len(proc_num) == 1 : proc_num = proc_num[0]\n",
    "    # print(proc_num)\n",
    "\n",
    "    acordaos = list(set(re.findall(regex_num_ac, texto_ac))) # localiza nº processo e exclui repetições\n",
    "    # print(acordaos)\n",
    "\n",
    "    texto_ac = re.sub('\\n', ' ', texto_ac)\n",
    "    # print(texto_ac)\n",
    "    # pyperclip.copy(texto_ac)\n",
    "\n",
    "    regex_relatorio = '(?:Relatório)(.*?)(?:Voto)'\n",
    "    try:\n",
    "        relatorio = re.findall(regex_relatorio, texto_ac, re.IGNORECASE)[0]\n",
    "        max(len(re) for re in relatorio)\n",
    "    except: \n",
    "        relatorio = \"Não encontrado\"\n",
    "    # print (relatorio)\n",
    "\n",
    "    regex_voto = '(?:Voto)(.*?)($)'\n",
    "    try:\n",
    "        voto = re.findall(regex_voto, texto_ac, re.IGNORECASE)[0]\n",
    "        max(len(vo) for vo in voto)\n",
    "    except:\n",
    "        voto = \"Não encontrado\"\n",
    "    # print (voto)\n",
    "\n",
    "    colunas = ['Processo', 'Decisao', 'Relatorio', 'Voto']\n",
    "    dados = [proc_num, acordaos, relatorio, voto]\n",
    "    inserir = {'Processo': proc_num, 'Decisao':list(acordaos), 'Relatorio':relatorio, 'Voto':voto}\n",
    "\n",
    "    db_acordao = pd.DataFrame(columns = colunas)\n",
    "    db_acordao = db_acordao.append(inserir, ignore_index=True)\n",
    "\n",
    "    return db_acordao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colunas = ['Processo', 'Decisao', 'Relatorio', 'Voto']\n",
    "\n",
    "db_acordao = pd.DataFrame(columns = colunas)\n",
    "\n",
    "for i in range(1,len(data_prec)-1):\n",
    "    if i in [] : continue\n",
    "    # print(i)\n",
    "    db_acordao2 = extrai_texto_acordao(data_prec['Completo'][i])\n",
    "    frames = [db_acordao, db_acordao2]\n",
    "    db_acordao = pd.concat(frames)\n",
    "\n",
    "db_acordao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir()\n",
    "# os.getcwd()\n",
    "os.chdir('d:\\\\Users\\\\Patri\\\\Documents\\\\1.TCC\\\\Notebooks\\\\WebscrapSúmula\\\\PDF Súmulas\\\\XML\\\\Acordao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_precedentes = pd.read_csv('dataset_precedentes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "df = db_acordao\n",
    "\n",
    "# Recebe um texto ou series e retorna os tokens\n",
    "def tokeniza(texto):\n",
    "    if type(texto) == \"Series\":\n",
    "        acordao_text = texto.to_string()\n",
    "    else:\n",
    "        acordao_text = str(texto)\n",
    "    acordao_text = acordao_text.lower() # coloca tudo em minúsculo\n",
    "    acordao_words = RegexpTokenizer(r'\\w+') # remove pontuação ao selecionar apenas palavras\n",
    "    acordao_tokens = acordao_words.tokenize(acordao_text) # tokeniza (separa as palavras)\n",
    "\n",
    "    # Extrair Stopwords em Português\n",
    "    pt_stops = set(stopwords.words('portuguese'))\n",
    "    pt_stops.update(['fls', 'cuida', 'nº', 'º', 'ª', 'n', 'fl'])\n",
    "    words = (acordao_tokens)\n",
    "    lista_words = [word for word in words if word not in pt_stops] # remove stopwords\n",
    "    if not len(lista_words): lista_words = []\n",
    "    return lista_words \n",
    "\n",
    "# Remove números de um texto\n",
    "def remove_numeros(texto):\n",
    "    output = ''.join(c for c in texto if not c.isdigit())\n",
    "    return output\n",
    "\n",
    "def lemma(texto):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(texto)\n",
    "\n",
    "\n",
    "# Tokeniza trechos do acórdão e salva tokens em uma nova coluna\n",
    "colunas=['Voto', 'Relatorio']\n",
    "\n",
    "for coluna in colunas:\n",
    "    df['t_'+coluna] = df[coluna].apply(tokeniza)\n",
    "\n",
    "coluna = 'Relatorio'\n",
    "# df['t0_'+coluna] = df[coluna].apply(tokeniza(remove_numeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0,'S057VO', 1) # adiciona coluna rotulando como True para a Sùmula 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_precedentes = df[['Relatorio', 'S057VO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_precedentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'd:\\\\Users\\\\Patri\\\\Documents\\\\1.TCC\\\\Notebooks\\\\WebScrapAcordaosPDF\\\\NLTK'\n",
    "dataset_precedentes.to_csv(path+'\\\\dataset_precedentes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd03ea523bc2d4f869847872ce3cd57df8231ee0b54777ea6b7d40abc7c29d8b996",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}