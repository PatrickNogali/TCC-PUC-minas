{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'd:\\\\Users\\\\Patri\\\\Documents\\\\1.TCC\\\\Notebooks\\\\WebScrapAcordaosPDF\\\\NLTK'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Ler Arquivo gravado com todo o tratamento dado até aqui\n",
    "# dfcsv = pd.read_csv('Acordaos2020booleado.csv')\n",
    "dfcsv = pd.read_csv('Acordaos2020tx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_num = 137\n",
    "sum_str = 'S'+str(sum_num).zfill(3)     #S999\n",
    "sum_RE = sum_str + 'RE'\n",
    "sum_VO = sum_str + 'VO'\n",
    "\n",
    "dfcsv[[sum_RE, sum_VO]].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RE0 = dfcsv.query(sum_RE + ' == 0')   # Selecionar apenas acórdãos cujos relatórios não mencionaram a súmula \n",
    "df_RE0[[sum_RE, sum_VO]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, validation = train_test_split(df_RE0, train_size = 2000)\n",
    "\n",
    "train, test = train_test_split(df)\n",
    "\n",
    "print(len (df), len (train), len (test), len (validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Decisao', 'Relatorio', sum_VO]]\n",
    "df = df.reset_index(drop = True)\n",
    "dataset_2020 = df\n",
    "dataset_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nltk = dataset_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'd:\\\\Users\\\\Patri\\\\Documents\\\\1.TCC\\\\Notebooks\\\\WebScrapAcordaosPDF\\\\NLTK'\n",
    "dataset_precedentes = pd.read_csv(path+'\\\\dataset_precedentes_' + str(sum_num) + '.csv')\n",
    "dataset_precedentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nltk = pd.concat ([dataset_2020, dataset_precedentes], ignore_index=True)\n",
    "dataset_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset_nltk)\n",
    "\n",
    "# model generation\n",
    "X_train = train['Relatorio']\n",
    "y_train = train[sum_VO]\n",
    "X_test = test['Relatorio']\n",
    "y_test = test[sum_VO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('TFIDF', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('classification', MultinomialNB())\n",
    "    ])\n",
    "pipe.fit(X_train,y_train)\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, predicted))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, predicted))\n",
    "conf_mnnb = confusion_matrix(y_test, predicted)\n",
    "conf_mnnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('TFIDF', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('classification', LogisticRegression())\n",
    "    ])\n",
    "pipe.fit(X_train,y_train)\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, predicted))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, predicted))\n",
    "conf_mnnb = confusion_matrix(y_test, predicted)\n",
    "conf_mnnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('TFIDF', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('classification', RandomForestClassifier())\n",
    "    ])\n",
    "pipe.fit(X_train,y_train)\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, predicted))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, predicted))\n",
    "conf_mnnb = confusion_matrix(y_test, predicted)\n",
    "conf_mnnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import regex as re\n",
    "import requests\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_nltk\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Recebe um texto ou series e retorna os tokens\n",
    "def tokeniza(texto):\n",
    "    if type(texto) == \"Series\":\n",
    "        acordao_text = texto.to_string()\n",
    "    else:\n",
    "        acordao_text = str(texto)\n",
    "    acordao_text = acordao_text.lower() # coloca tudo em minúsculo\n",
    "    acordao_text = re.sub('(º)', ' ', acordao_text) # remove 'º' substituindo por espaço\n",
    "    acordao_words = RegexpTokenizer(r'\\w+') # remove pontuação ao selecionar apenas palavras\n",
    "    acordao_tokens = acordao_words.tokenize(acordao_text) # tokeniza (separa as palavras)\n",
    "\n",
    "    # Extrair Stopwords em Português\n",
    "    pt_stops = set(stopwords.words('portuguese'))\n",
    "    pt_stops.update(['fls', 'cuida', 'ª', 'n', 'fl'])\n",
    "    words = (acordao_tokens)\n",
    "    lista_words = [word for word in words if word not in pt_stops] # remove stopwords\n",
    "    if not len(lista_words): lista_words = []\n",
    "    return lista_words \n",
    "\n",
    "# Remove números de um texto\n",
    "def remove_numeros(texto):\n",
    "    output = ' '.join(c for c in texto if not c.isdigit())\n",
    "    return output\n",
    "\n",
    "def lemma(x):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens']=df['Relatorio'].map(tokeniza)\n",
    "df['lemma'] = df['tokens'].map(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemma'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptstopwords = ['º', 'ª', 'a', 'ainda', 'ao', 'aos', 'apenas', 'apos', 'após', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'art', 'artigo', 'arts', 'as', 'assim', 'assunto', 'até', 'brasil', 'cabe', 'caracteriza', 'caso', 'com', 'como', 'conforme', 'correspondente', 'da', 'das', 'data', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'desde', 'direito', 'do', 'dos', 'e', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'essa', 'essas', 'esse', 'esses', 'esta', 'estamos', 'estas', 'estava', 'estavam', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéramos', 'estivéssemos', 'estou', 'está', 'estávamos', 'estão', 'eu', 'falar', 'fl', 'fls', 'foi', 'fomos', 'for', 'fora', 'foram', 'forem', 'formos', 'fosse', 'fossem', 'fui', 'fôramos', 'fôssemos', 'haja', 'hajam', 'hajamos', 'havemos', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houveram', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houvermos', 'houverá', 'houverão', 'houveríamos', 'houvesse', 'houvessem', 'houvéramos', 'houvéssemos', 'há', 'hão', 'ii', 'in', 'inciso', 'isso', 'isto', 'já', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesma', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito', 'n', 'na', 'nao', 'nas', 'nem', 'no', 'nos', 'nossa', 'nossas', 'n', 'nosso', 'nossos', 'num', 'numa', 'nº', 'não', 'nós', 'o', 'os', 'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'pode', 'pois', 'por', 'qual', 'qualquer', 'quando', 'quanto', 'que', 'quem', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'sendo', 'ser', 'serei', 'seremos', 'seria', 'seriam', 'será', 'serão', 'seríamos', 'seu', 'seus', 'sido', 'sobre', 'somos', 'sou', 'sua', 'suas', 'são', 'só', 'tais', 'tal', 'tambem', 'também', 'te', 'tem', 'temos', 'tendo', 'tenha', 'tenham', 'tenhamos', 'tenho', 'ter', 'terei', 'teremos', 'teria', 'teriam', 'termos', 'terá', 'terão', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéramos', 'tivéssemos', 'todos', 'trata', 'tu', 'tua', 'tuas', 'tém', 'tínhamos', 'um', 'uma', 'valor', 'valores', 'vez', 'você', 'vocês', 'vos', 'à', 'às', 'é', 'éramos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['lemma']\n",
    "y = df[sum_VO]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mnnb = Pipeline(steps = [('tf', TfidfVectorizer()), ('mnnb', MultinomialNB())])\n",
    "\n",
    "pgrid_mnnb = {\n",
    " 'tf__max_features' : [1000, 2000, 3000],\n",
    " 'tf__stop_words' : ['portuguese', None, ptstopwords],\n",
    " 'tf__ngram_range' : [(1,1),(1,2)],\n",
    " 'tf__use_idf' : [True, False],\n",
    " 'mnnb__alpha' : [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "gs_mnnb = GridSearchCV(pipe_mnnb,pgrid_mnnb,cv=5,n_jobs=-1)\n",
    "gs_mnnb.fit(X_train, y_train)\n",
    "preds_mnnb = gs_mnnb.predict(X)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y, preds_mnnb))\n",
    "print(\"Precision:\",metrics.precision_score(y, preds_mnnb))\n",
    "print(\"Recall:\",metrics.recall_score(y, preds_mnnb))\n",
    "conf_mnnb = confusion_matrix(y, preds_mnnb)\n",
    "print(conf_mnnb)\n",
    "gs_mnnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preds'] = preds_mnnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[sum_VO]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[sum_VO,'preds']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[sum_VO,'preds']].query(sum_VO + ' == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd03ea523bc2d4f869847872ce3cd57df8231ee0b54777ea6b7d40abc7c29d8b996",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}